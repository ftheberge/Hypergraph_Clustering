{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the following packages:\n",
    "\n",
    "* pip install python-igraph\n",
    "* pip install partition-igraph\n",
    "* pip install hypernetx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import partition_igraph\n",
    "import hypernetx as hnx\n",
    "import pickle\n",
    "\n",
    "## import the hypergraph functions -- HNX version\n",
    "get_ipython().magic('run ./H_functions.py');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of functions for HNX hypergraphs\n",
    "\n",
    "### Build hypergraph and pre-compute key quantities\n",
    "\n",
    "We build the hypergraph HG using:\n",
    "\n",
    "```python\n",
    "HG = hnx.Hypergraph(dict(enumerate(Edges)))\n",
    "```\n",
    "\n",
    "where 'Edges' is a list of sets; edges are then indexed as 0-based integers,\n",
    "so to preserve unique ids, we represent nodes as strings.\n",
    "For example Edges[0] = {'0','2'}\n",
    "\n",
    "Once the HNX hypergraph is built, the following function is called to \n",
    "compute node strengths, d-degrees and binomial coefficients:\n",
    "\n",
    "```python\n",
    "HNX_precompute(HG)\n",
    "```\n",
    "\n",
    "### Partitions\n",
    "\n",
    "We use two representations for partitions: list of sets (the parts) or dictionary.\n",
    "Those functions are used to map from one to the other:\n",
    "\n",
    "```python\n",
    "dict2part(D)\n",
    "part2dict(A)\n",
    "```\n",
    "\n",
    "### H-modularity\n",
    "\n",
    "The function to compute H-modularity for HG w.r.t. partition A (list of sets covering the vertices):\n",
    "\n",
    "```python\n",
    "HNX_modularity(HG, A, wcd=linear)\n",
    "```\n",
    "\n",
    "where 'wcd' is the weight function (default = 'linear'). Other choices are 'strict'\n",
    "and 'majority', or any user-supplied function with the following format:\n",
    "\n",
    "```python\n",
    "def linear(d,c):\n",
    "    return c/d if c>d/2 else 0\n",
    "```\n",
    "\n",
    "where d is the edge size, and d>=c>d/2 the number of nodes in the majority class.\n",
    "\n",
    "### Two-section graph\n",
    "\n",
    "Build the random-walk based 2-section graph given some hypergraph HG:\n",
    "\n",
    "```python\n",
    "G = HNX_2section(HG)\n",
    "```\n",
    "\n",
    "where G is an igraph Graph.\n",
    "\n",
    "### Clustering: Kumar algorithm\n",
    "\n",
    "Given hypergraph HG, compute a partition of the vertices as per Kumar's algorithm described in [1].\n",
    "\n",
    "```python\n",
    "K = HNX_Kumar(HG, delta=.01)\n",
    "```\n",
    "\n",
    "where delta is the convergence stopping criterion. Partition is returned as a dictionary.\n",
    "\n",
    "[1] Kumar T., Vaidyanathan S., Ananthapadmanabhan H., Parthasarathy S., Ravindran B. (2020) *A New Measure of Modularity in Hypergraphs: Theoretical Insights and Implications for Effective Clustering*. In: Cherifi H., Gaito S., Mendes J., Moro E., Rocha L. (eds) Complex Networks and Their Applications VIII. COMPLEX NETWORKS 2019. Studies in Computational Intelligence, vol 881. Springer, Cham. https://doi.org/10.1007/978-3-030-36687-2_24\n",
    "\n",
    "\n",
    "### Clustering: Simple qH-based algorithm\n",
    "\n",
    "Given hypergraph HG and initial partition L, \n",
    "compute a partition of the vertices as per Last-Step algorithm described in [2].\n",
    "\n",
    "```python\n",
    "A = HNX_LastStep(HG, L, wdc=linear, delta = .01)\n",
    "```\n",
    "\n",
    "where 'wcd' is the the weight function (default = 'linear') and delta is the convergence stopping criterion.\n",
    "Returned partition is a list of sets.\n",
    "\n",
    "[2] B. Kaminski, P. Pralat and F. Th√©berge, *Community Detection Algorithm Using Hypergraph Modularity*, to appear in the proceedings of Complex Networks 2020, Springer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build an hypergraph from a list of sets (the hyperedges)\n",
    "## using 'enumerate', edges will have integer IDs\n",
    "E = [{'A','B'},{'A','C'},{'A','B','C'},{'A','D','E','F'},{'D','F'},{'E','F'}]\n",
    "HG = hnx.Hypergraph(dict(enumerate(E)))\n",
    "hnx.draw(HG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute node strength (add unit weight is none), d-degrees, binomial coefficients\n",
    "HNX_precompute(HG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the edges (unit weights added by default)\n",
    "HG.edges.elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the nodes (here strength = degree since all weights are 1)\n",
    "HG.nodes.elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HG.d_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute modularity qH for the following partitions:\n",
    "A1 = [{'A','B','C'},{'D','E','F'}]\n",
    "A2 = [{'B','C'},{'A','D','E','F'}]\n",
    "A3 = [{'A','B','C','D','E','F'}]\n",
    "A4 = [{'A'},{'B'},{'C'},{'D'},{'E'},{'F'}]\n",
    "\n",
    "print('linear:',HNX_modularity(HG,A1),HNX_modularity(HG,A2),HNX_modularity(HG,A3),HNX_modularity(HG,A4))\n",
    "print('strict:',HNX_modularity(HG,A1,strict),HNX_modularity(HG,A2,strict),HNX_modularity(HG,A3,strict),HNX_modularity(HG,A4,strict))\n",
    "print('majority:',HNX_modularity(HG,A1,majority),HNX_modularity(HG,A2,majority),HNX_modularity(HG,A3,majority),HNX_modularity(HG,A4,majority))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2-section graph\n",
    "G = HNX_2section(HG)\n",
    "G.vs['label'] = G.vs['name']\n",
    "ig.plot(G,bbox=(0,0,250,250))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2-section clustering with ECG\n",
    "G.vs['community'] = G.community_ecg().membership\n",
    "dict2part({v['name']:v['community'] for v in G.vs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clustering with Kumar's algorithm\n",
    "dict2part(HNX_Kumar(HG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hypergraph clustering -- start from partition A4 defined above\n",
    "print('start from:',A4)\n",
    "A = HNX_LastStep(HG,A4)\n",
    "print('final partition:',A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game of Thrones scenes hypergraph\n",
    "\n",
    "REF: https://github.com/jeffreylancaster/game-of-thrones\n",
    "\n",
    "We built an hypergraph from the game of thrones scenes with he following elements:\n",
    "\n",
    "* **Nodes** are characters in the series\n",
    "* **Hyperedges** are groups of character appearing in the same scene(s)\n",
    "* **Hyperedge weights** are total scene(s) duration in seconds involving those characters\n",
    "\n",
    "We kept hyperedges with at least 2 characters.\n",
    "Moreover, we discarded characters with degree below 5.\n",
    "\n",
    "We saved the following:\n",
    "\n",
    "* *Edges*: list of sets where the nodes are 0-based integers represents as strings\n",
    "* *Names*: dictionary; mapping of nodes to character names\n",
    "* *Weights*: list; hyperedge weights (in same order as Edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the GoT dataset\n",
    "Edges, Names, Weights = pickle.load(open( \"../Data/GoT.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build weighted hypergraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nodes are represented as strings from '0' to 'n-1'\n",
    "HG = hnx.Hypergraph(dict(enumerate(Edges)))\n",
    "## add edge weights\n",
    "for e in HG.edges:\n",
    "    HG.edges[e].weight = Weights[e]\n",
    "## add full names\n",
    "for v in HG.nodes:\n",
    "    HG.nodes[v].name = Names[v]\n",
    "## pre-compute required quantities for modularity and clustering\n",
    "HNX_precompute(HG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularity (qH) on a random partition\n",
    "\n",
    "Should be close to 0 and can be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate a random partition into K parts to compare results\n",
    "K = 5\n",
    "V = list(HG.nodes)\n",
    "p = np.random.choice(K, size=len(V))\n",
    "RandPart = dict2part({V[i]:p[i] for i in range(len(V))})\n",
    "## compute qH\n",
    "HNX_modularity(HG, RandPart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the 2-section graph (with igraph) and cluster with Louvain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build 2-section\n",
    "G = HNX_2section(HG)\n",
    "## Louvain algorithm\n",
    "ML = G.community_multilevel(weights='weight')\n",
    "G.vs['louvain'] = ML.membership\n",
    "part = dict2part({v['name']:v['louvain'] for v in G.vs})\n",
    "## Compute qH\n",
    "print(HNX_modularity(HG, part))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with Kumar's algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run Kumar's algorithm, get partition\n",
    "KU = HNX_Kumar(HG)\n",
    "G.vs['kumar'] = [KU[v['name']] for v in G.vs]\n",
    "## Compute qH\n",
    "print(HNX_modularity(HG, dict2part(KU)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with simple H-based (Last Step) Algorithm\n",
    "\n",
    "We use Louvain or Kumar algorithm on the 2-section as the required initial partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Louvain parition already computed\n",
    "part = dict2part({v['name']:v['louvain'] for v in G.vs})\n",
    "## H-based last step\n",
    "LS = HNX_LastStep(HG, part)\n",
    "## Compute qH\n",
    "HNX_modularity(HG, LS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: top nodes in cluster with Daenerys Targaryen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Index for \n",
    "inv_map = {v: k for k, v in Names.items()}\n",
    "JS = inv_map['Daenerys Targaryen']\n",
    "## JS's cluster\n",
    "JS_part = part2dict(LS)[JS]\n",
    "## Build dataframe: all nodes in JS_part\n",
    "L = []\n",
    "for n in LS[JS_part]:\n",
    "    L.append([Names[n],HG.nodes[n].strength])\n",
    "D = pd.DataFrame(L, columns=['character','strength'])\n",
    "D.sort_values(by='strength',ascending=False).head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
